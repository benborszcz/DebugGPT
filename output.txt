# LICENSE
```
MIT License

Copyright (c) 2023 benborszcz

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

```

# README.md
```
# DebugGPT
```

# requirements.txt
```
python-dotenv
openai
backoff
rich
inquirer
```

# setup.py
```
from setuptools import setup, find_packages

setup(
    name='DebugGPT',
    version='0.1',
    packages=find_packages(),
    include_package_data=True,
    install_requires=[
        'python-dotenv',
        'openai',
        'backoff',
        'rich',
        'inquirer',
    ],
    entry_points={
        'console_scripts': [
            'dgpt=dgpt.cli:main',
        ],
    },
)


```

# dgpt\agent.py
```
from . import config
import openai
import json
import backoff

# Set the API Params for OpenAI
openai.api_key = config.OPENAI_API_KEY

class Agent:
    def __init__(self, id, system: str = "You are a helpful assistant", additional_messages: list = None, functions: list = None):
        self.id = id
        self.system = system
        self.additional_messages = additional_messages
        self.functions = {}
        if functions != None:
            for function in functions:
                self.functions[function.name] = function
        else:
            self.functions = functions
    
    def generate(self, messages: list, temperature=0.1, presence_penalty=0.0, frequency_penalty=0.0, max_tokens=1000):      
        local_messages = []
        local_messages.extend(messages)
        local_messages.insert(0, {"role": "system", "content": self.system})
        if self.additional_messages != None: local_messages.insert(1, self.additional_messages)
        response = self.chat_completion(local_messages)
        return response
    
    @backoff.on_exception(backoff.expo, Exception, max_tries=3, on_backoff=lambda details: print(f"Retrying for the {details['tries']} time"))
    def chat_completion(self, messages: list, temperature=0.4, presence_penalty=0.1, frequency_penalty=0.1, max_tokens=1000):
        # Generate a response using the OpenAI API
        if self.functions == None:
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo-0613",
                messages=messages,
                temperature=temperature,
                presence_penalty=presence_penalty,
                frequency_penalty=frequency_penalty,
                max_tokens=max_tokens,
            )
            return response
        else:
            passed_functions = []
            function_response = None
            for key, value in self.functions.items():
                passed_functions.append(value.to_dict())

            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo-0613",
                messages=messages,
                temperature=temperature,
                presence_penalty=presence_penalty,
                frequency_penalty=frequency_penalty,
                max_tokens=max_tokens,
                functions=passed_functions
            )
            response_message = response["choices"][0]["message"]
            if response_message.get("function_call"):
                # Step 3: call the function
                # Note: the JSON response may not always be valid; be sure to handle errors
                function_name = response_message["function_call"]["name"]
                fuction_to_call = self.functions[function_name]
                function_args = json.loads(response_message["function_call"]["arguments"])
                function_response = fuction_to_call.process_instruction(function_args)
                return {'choices': [{'message': {'content':function_response}}]}
            return response
        
    
            
```

# dgpt\agent_manager.py
```
from .agent import Agent
from .get_files import GetFiles
from .edit_file import EditFile

class AgentManager:
    def __init__(self):
        self.agents = {
            "Chat": Agent("Chat"),
            "ErrorAnalysis": Agent("ErrorAnalysis", "You analyze programming error codes, identify the files invloved, and explain the error in natural language."),
            "FileRequester": Agent("FileRequester", "Given a natural language representation of a programming error code, you: request the necessary files to read to solve the error. You will be able to request multiple files in multiple steps.", functions=[GetFiles()]),
            "StepPlanner": Agent("StepPlanner", "Given a natural language representation of a programming error code and the necessary files to read, you give a step by step plan to solve the problem. The plan you are giving is to another language model that has access to edit files. It does not run code. It can edit a file by calling the tool edit_file(file, new_contents), where the new_contents are the entirety of the files contents with the error fixed. That is the ONLY thing it has access to. Solve it in the simplest way possible. The instructions should be verbal, not code."),
            "CodeModifier": Agent("CodeModifier", "Given a natural language representation of a programming error code, the necessary files, and a step by step plan to fix the error, you follow the steps and generate the necessary code to solve the problem. You can only call the functions provided", functions=[EditFile()]),
            "ErrorComparison": Agent("ErrorComparison", "Given two errors, you compare them and see if progress was made in debugging."),
            "ProgressIdentifier": Agent("ProgressIdentifier", "Given a passage comparing two errors to see if progress was made identify if it was, respond 't' for yes and 'f' for no. Do NOT generate any other characters."),
            "Revert": Agent("Revert")
        }

    def generate(self, agent_id: str, messages: list = None):
        if messages == None : messages = []

        response = self.agents[agent_id].generate(messages=messages)

        response_message = response['choices'][0]['message']['content']
        return response_message
```

# dgpt\change_logger.py
```
import os
import shutil
import difflib
import time
from collections import deque
from filecmp import dircmp
import os

class ChangeLogger:
    def __init__(self, directory):
        self.directory = directory
        self.backup_directory = f"{os.getcwd()}\\backup"
        self.changes = deque()
        self.create_backup()

    def create_backup(self):
        if os.path.exists(self.backup_directory):
            shutil.rmtree(self.backup_directory, ignore_errors=True)
        shutil.copytree(self.directory, self.backup_directory, ignore=shutil.ignore_patterns('.git'))

    def check_changes(self):
        comparison = dircmp(self.directory, self.backup_directory)
        self.handle_differences(comparison)

    def handle_differences(self, comparison):
        for file in comparison.diff_files:
            original_file = os.path.join(self.backup_directory, file)
            changed_file = os.path.join(self.directory, file)
            with open(original_file, 'r') as f1, open(changed_file, 'r') as f2:
                diff = difflib.unified_diff(
                    f1.readlines(),
                    f2.readlines(),
                    fromfile=original_file,
                    tofile=changed_file,
                )
                self.changes.appendleft((time.time(), ''.join(diff), changed_file))
                #shutil.copy2(changed_file, original_file)  # update backup

    def revert_last_change(self):
        if self.changes:
            _, _, changed_file = self.changes.popleft()
            backup_file = os.path.join(self.backup_directory, os.path.basename(changed_file))
            shutil.copy2(backup_file, changed_file)  # revert to backup

    def display_changes(self):
        for change_time, diff, _ in self.changes:
            print(f"Time: {time.ctime(change_time)}")
            print(diff)

    def get_versions(self):
        versions = []
        for _, _, file in self.changes:
            with open(file, 'r') as f:
                versions.append((file, f.read()))
        return versions
```

# dgpt\cli.py
```
from .script_runner import ScriptRunner
from .agent_manager import AgentManager
from .change_logger import ChangeLogger
import os
from rich.console import Console
from rich.progress import Progress
from rich.traceback import install
from rich import print as rprint
import inquirer
import time

install()

console = Console()

manager = AgentManager()

def debug_script(script):
    change_logger = ChangeLogger(os.path.dirname(os.path.abspath(script)))
    runner = ScriptRunner(script)
    console.print(f"-----Running {script}-----", style="bold blue")
    status, output = runner.run_script()
    console.print(output)
    if not status:
        console.print("-----Analyzing Output-----", style="bold blue")
        error_analysis_output = manager.generate("ErrorAnalysis", [{"role":"user","content":output}])
        console.print(error_analysis_output, style="bold red")
        console.print("-----Requesting Files-----", style="bold blue")
        file_getter_output = manager.generate("FileRequester", [{"role":"user","content":str(error_analysis_output)}])
        console.print(file_getter_output, style="bold green")
        console.print("-----Planning Solution-----", style="bold blue")
        step_planner_output = manager.generate("StepPlanner", [{"role":"user","content":(str(error_analysis_output)+"\n\n"+str(file_getter_output))}])
        console.print(step_planner_output, style="bold green")
        console.print("-----Editing Files-----", style="bold blue")
        code_modifier_output = manager.generate("CodeModifier", [{"role":"user","content":(str(error_analysis_output)+"\n\n"+str(file_getter_output)+"\n\n"+str(step_planner_output))}])
        console.print(code_modifier_output, style="bold green")
        change_logger.check_changes()
        console.print(f"-----Running {script}-----", style="bold blue")
        runner = ScriptRunner(script)
        status, new_output = runner.run_script()
        console.print(new_output)
        
        progress_id_output = 'f'

        if not status:
            console.print("DebugGPT has identified another/new error", style="bold red")
            console.print("-----Analyzing Output-----", style="bold blue")
            edit_analysis_output = manager.generate("ErrorAnalysis", [{"role":"user","content":new_output}])
            console.print(edit_analysis_output, style="bold red")
            console.print("-----Analyzing Progress-----", style="bold blue")
            compare_errors_output = manager.generate("ErrorComparison", [{"role":"user","content":f"Old Error: {str(error_analysis_output)}\n\nNew Error:{str(edit_analysis_output)}"}])
            console.print(compare_errors_output, style="bold green")
            progress_id_output = manager.generate("ProgressIdentifier", [{"role":"user","content":str(compare_errors_output)}])
            if progress_id_output == 't': console.print("%%DebugGPT has identified progress was made", style="bold green")
            else: console.print("%%DebugGPT has identified no/reverse progress was made", style="bold red")
        
        console.print("-----Deciding Next Step-----", style="bold blue")
        console.print("***User Input Required***", style="bold yellow")
        change_logger.display_changes()
        questions = [
            inquirer.List('choice',
                          message="Would you like to keep the above changes or revert?",
                          choices=['Continue', 'Revert'],
                          ),
        ]
        answers = inquirer.prompt(questions)
        if answers['choice'] == 'Continue':
            console.print("-----Continuing Debug-----", style="bold blue")
            debug_script(script)
        elif answers['choice'] == 'Revert':
            console.print("-----Reverting Changes-----", style="bold blue")
            change_logger.revert_last_change()
            console.print("-----Deciding Next Step-----", style="bold blue")
            console.print("***User Input Required***", style="bold yellow")
            questions = [
                inquirer.List('choice',
                              message="Would you like to try debugging again?",
                              choices=['Yes', 'No'],
                              ),
            ]
            answers = inquirer.prompt(questions)
            if answers['choice'] == 'No': return False
            console.print("-----Continuing Debug-----", style="bold blue")
            debug_script(script)
    return status

"""
console.rule("[bold blue]DebugGPT")
debug_script('main_errors.py')
console.print("All Errors Solved or DebugGPT Terminated", style="italic purple")
console.rule("[bold blue]https://github.com/benborszcz/DebugGPT")
"""
import sys

def main():
    if len(sys.argv) != 2:
        print("Usage: dgpt file_name.py")
        sys.exit(1)

    script_file = sys.argv[1]
    console.rule("[bold blue]DebugGPT")
    debug_script(script_file)
    console.print("All Errors Solved or DebugGPT Terminated", style="italic purple")
    console.rule("[bold blue]https://github.com/benborszcz/DebugGPT")
```

# dgpt\config.py
```
import os
from dotenv import load_dotenv

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

DEBUG = True
```

# dgpt\edit_file.py
```
from .function import Function
import os

class EditFile(Function):

    def __init__(self):
        self.name="edit_file"
        self.description="allows for the editing of files"
        self.parameters={
            "type": "object",
            "properties": {
                "file": {
                    "type": "string",
                    "description": "name of the file",
                },
                "new_contents": {
                    "type": "string",
                    "description": "new contents of the file, you must write the entire file",
                },
            },
            "required": ["file", "new_contents"],
        }
        super().__init__(self.name, self.description, self.parameters)       


    def process_instruction(self, function_args) -> str:
        file = function_args.get('file')
        new_contents = function_args.get('new_contents')

        if not os.path.exists(file):
            return f"File {file} does not exist."

        try:
            with open(file, 'w') as f:
                f.write(new_contents)

            # Delete specific .pyc file in __pycache__ if it exists
            pycache_file = os.path.join(os.path.dirname(file), "__pycache__", os.path.basename(file).split('.')[0] + ".cpython-XX.pyc")
            pycache_file = pycache_file.replace("XX", str(os.sys.version_info.major) + str(os.sys.version_info.minor)) # replace XX with current python version
            if os.path.exists(pycache_file):
                os.remove(pycache_file)

            return f"File {file} has been successfully edited and associated .pyc file deleted."
        except Exception as e:
            return "Error: "+str(e)
```

# dgpt\function.py
```
from abc import ABC, abstractmethod

class Function(ABC):

    def __init__(self, name, description, parameters):
        self.name = name
        self.description = description
        self.parameters = parameters

    def to_dict(self):
        return {
            "name": self.name,
            "description": self.description,
            "parameters": self.parameters
        }
        
    @abstractmethod
    def process_instruction(self, function_args) -> str:
        pass
```

# dgpt\get_files.py
```
from .function import Function
import os

class GetFiles(Function):

    def __init__(self):
        self.name="get_files"
        self.description="Gets the files asked for"
        self.parameters={
            "type": "object",
            "properties": {
                "files": {
                    "type": "string",
                    "description": "names of the files required, separated by spaces.",
                }
            },
            "required": ["files"],
        }
        super().__init__(self.name, self.description, self.parameters)       


    def process_instruction(self, function_args) -> str:
        files = function_args.get('files', "").split()
        result = ""

        for file in files:
            if os.path.exists(file):
                with open(file, 'r') as f:
                    content = f.read()
                result += f"# {file}\n```{file.split('.')[-1]}\n{content}\n```\n\n"
            else:
                result += f"# {file}\n```File not found```\n\n"

        return result



```

# dgpt\script_runner.py
```
import subprocess
import traceback

class ScriptRunner:

    def __init__(self, script_path):
        self.script_path = script_path

    def run_script(self):
        try:
            result = subprocess.run(['python', self.script_path], capture_output=True, text=True)
            if result.returncode == 0:
                return True, f"Running {self.script_path} Successful"
            else:
                return False, result.stderr
        except Exception as e:
            return False, "".join(traceback.format_exception(type(e), e, e.__traceback__))
```

